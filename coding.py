# -*- coding: utf-8 -*-
"""Coding.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DqfLiAMpN0ktKqEcf9B7aT9V-4rYnM23
"""

# ============================================================
# Colab All-in-One: Methodology + Results + EDA + KPIs + Figures
# ============================================================
# HOW TO RUN:
# 1) Paste this in a single Colab cell and run.
# 2) If /content/Dataset.csv doesn't exist, you'll be prompted to upload.
# 3) Outputs are saved to /content/output/
# ------------------------------------------------------------

# --- Installs (for Colab) ---
!pip -q install graphviz==0.20.3
!apt-get -qq update && apt-get -qq install -y graphviz > /dev/null

# --- Imports ---
import os, io, json, math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from pathlib import Path
from typing import Optional
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,
    mean_absolute_error, mean_squared_error, r2_score
)
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor

try:
    from graphviz import Digraph
    HAS_GRAPHVIZ = True
except Exception as e:
    HAS_GRAPHVIZ = False

# --- Paths ---
BASE = Path("/content")
OUT = BASE / "output"
OUT.mkdir(parents=True, exist_ok=True)
DATA_PATH = BASE / "Dataset.csv"

# --- Load dataset (upload if not present) ---
if not DATA_PATH.exists():
    try:
        from google.colab import files
        print("Upload your CSV (will be saved as Dataset.csv)...")
        uploaded = files.upload()
        key = list(uploaded.keys())[0]
        os.rename(key, DATA_PATH) if key != "Dataset.csv" else None
    except Exception as e:
        raise RuntimeError("Please upload your dataset to /content or via files.upload()") from e

df = pd.read_csv(DATA_PATH)
print("Loaded data:", df.shape)
display(df.head(5))

# --- Basic info ---
print("\n--- DTypes ---")
print(df.dtypes)
print("\n--- Missing (count) ---")
print(df.isna().sum())
print("\n--- Duplicate rows ---")
print(df.duplicated().sum())
print("\n--- Memory usage (bytes) ---")
print(df.memory_usage(deep=True).sum())

# --- Try to parse datetime-like object columns ---
def try_parse_datetime(col: pd.Series) -> Optional[pd.Series]:
    n = min(len(col), 200)
    ok = 0
    for val in col.dropna().astype(str).head(n):
        try:
            _ = pd.to_datetime(val, errors='raise')
            ok += 1
        except:
            pass
    if n > 0 and ok / n >= 0.8:
        return pd.to_datetime(col, errors='coerce')
    return None

parsed = 0
for c in df.columns:
    if df[c].dtype == object:
        dt = try_parse_datetime(df[c])
        if dt is not None:
            df[c] = dt
            parsed += 1
print(f"\nDatetime columns parsed: {parsed}")

# --- Type splits ---
numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
categorical_cols = [c for c in df.columns if df[c].dtype == 'object']
datetime_cols = [c for c in df.columns if np.issubdtype(df[c].dtype, np.datetime64)]
print("\nNumeric:", numeric_cols)
print("Categorical:", categorical_cols)
print("Datetime:", datetime_cols)

# --- Missingness bar chart ---
miss = df.isna().sum().sort_values(ascending=False)
if miss.sum() > 0:
    plt.figure()
    plt.bar(miss.index.astype(str), miss.values)
    plt.title("Missing Values per Column")
    plt.xticks(rotation=90)
    plt.ylabel("Count")
    plt.tight_layout()
    plt.savefig(OUT / "missing_values.png", dpi=300)
    plt.show()

# --- Correlation heatmap (numeric only) ---
if len(numeric_cols) >= 2:
    corr = df[numeric_cols].corr(numeric_only=True)
    plt.figure()
    plt.imshow(corr, aspect='auto')
    plt.title("Correlation Matrix (numeric)")
    plt.xticks(range(len(numeric_cols)), numeric_cols, rotation=90)
    plt.yticks(range(len(numeric_cols)), numeric_cols)
    plt.colorbar()
    plt.tight_layout()
    plt.savefig(OUT / "correlation_matrix.png", dpi=300)
    plt.show()

# --- Target detection ---
target_candidates = [c for c in df.columns if c.lower() in ["target","label","class","y","outcome"]]
target_col = target_candidates[0] if target_candidates else df.columns[-1]
print("\nSelected target column:", target_col)
task_type = "regression" if pd.api.types.is_numeric_dtype(df[target_col]) else "classification"
print("Inferred task:", task_type)

# --- Split ---
X = df.drop(columns=[target_col]).copy()
y = df[target_col].copy()
num_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]
cat_cols = [c for c in X.columns if X[c].dtype == 'object']

numeric_transformer = Pipeline(steps=[('scaler', StandardScaler(with_mean=False))])
categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore', sparse=True))])
preprocess = ColumnTransformer(
    transformers=[('num', numeric_transformer, num_cols), ('cat', categorical_transformer, cat_cols)],
    remainder='drop'
)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y if task_type=='classification' else None
)
print("Train:", X_train.shape, "Test:", X_test.shape)

# --- Baseline models & plots ---
def regression_eval(name, model):
    pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, pred)
    rmse = mean_squared_error(y_test, pred, squared=False)
    r2 = r2_score(y_test, pred)
    print(f"{name} -> MAE={mae:.4f} RMSE={rmse:.4f} R2={r2:.4f}")
    plt.figure()
    plt.scatter(y_test, pred)
    plt.title(f"Predicted vs True: {name}")
    plt.xlabel("True")
    plt.ylabel("Predicted")
    plt.tight_layout()
    plt.savefig(OUT / f"pred_vs_true_{name}.png", dpi=300)
    plt.show()

def classification_eval(name, model):
    pred = model.predict(X_test)
    acc = accuracy_score(y_test, pred)
    prec = precision_score(y_test, pred, average='weighted', zero_division=0)
    rec = recall_score(y_test, pred, average='weighted', zero_division=0)
    f1 = f1_score(y_test, pred, average='weighted', zero_division=0)
    print(f"{name} -> Acc={acc:.3f} Prec={prec:.3f} Rec={rec:.3f} F1={f1:.3f}")
    cm = confusion_matrix(y_test, pred)
    plt.figure()
    plt.imshow(cm, aspect='auto')
    plt.title(f"Confusion Matrix: {name}")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.colorbar()
    plt.tight_layout()
    plt.savefig(OUT / f"confusion_matrix_{name}.png", dpi=300)
    plt.show()

if task_type == "classification":
    pipe_lr = Pipeline(steps=[('prep', preprocess), ('clf', LogisticRegression(max_iter=1000))])
    pipe_rf = Pipeline(steps=[('prep', preprocess), ('clf', RandomForestClassifier(n_estimators=300, random_state=42))])
    pipe_lr.fit(X_train, y_train); classification_eval("LogReg", pipe_lr)
    pipe_rf.fit(X_train, y_train); classification_eval("RF_Classifier", pipe_rf)
else:
    pipe_lin = Pipeline(steps=[('prep', preprocess), ('reg', LinearRegression())])
    pipe_rf  = Pipeline(steps=[('prep', preprocess), ('reg', RandomForestRegressor(n_estimators=300, random_state=42))])
    pipe_lin.fit(X_train, y_train); regression_eval("Linear", pipe_lin)
    pipe_rf.fit(X_train, y_train);  regression_eval("RF_Regressor", pipe_rf)

# --- Manuscript KPIs
kpis = {
    "processing_time_minutes": {"baseline": 10.0, "hybrid": 3.0},
    "error_rate_percent": {"baseline": 10.0, "hybrid": 1.5},
    "throughput_per_day": {"baseline": 180, "hybrid": 600},
    "non_compliance_per_100": {"baseline": 4.0, "hybrid": 0.0},
}
improvements = {
    "processing_time_minutes": round((10.0-3.0)/10.0*100, 1),
    "error_rate_percent": round((10.0-1.5)/10.0*100, 1),
    "throughput_per_day": round((600-180)/180*100, 1),
    "non_compliance_per_100": 100.0
}

# --- Table 1 (CSV + print) ---
table1 = pd.DataFrame({
    "Metric": [
        "Processing time per transcript (minutes)",
        "Error rate (%)",
        "Throughput (transcripts/day, same staffing)",
        "Non-compliance flags (per 100 transcripts)"
    ],
    "Baseline": [
        kpis["processing_time_minutes"]["baseline"],
        kpis["error_rate_percent"]["baseline"],
        kpis["throughput_per_day"]["baseline"],
        kpis["non_compliance_per_100"]["baseline"]
    ],
    "Hybrid": [
        kpis["processing_time_minutes"]["hybrid"],
        kpis["error_rate_percent"]["hybrid"],
        kpis["throughput_per_day"]["hybrid"],
        kpis["non_compliance_per_100"]["hybrid"]
    ],
    "Improvement (%)": [
        improvements["processing_time_minutes"],
        improvements["error_rate_percent"],
        improvements["throughput_per_day"],
        improvements["non_compliance_per_100"]
    ],
    "Definition / Notes": [
        "Average end-to-end time from request to delivery",
        "Mismatched/incorrect fields vs ground truth",
        "Normalized to identical staffing-hours and request mix",
        "Audit exceptions triggered by FERPA/GDPR rules"
    ]
})
table1_path = OUT / "table1_performance_metrics.csv"
table1.to_csv(table1_path, index=False)
print("\n--- Table 1 ---")
display(table1)
print("Saved:", table1_path)

# --- Figure 2: Processing time (bar) ---
plt.figure()
plt.bar(["Baseline", "Hybrid"], [kpis["processing_time_minutes"]["baseline"], kpis["processing_time_minutes"]["hybrid"]])
plt.title("Processing Time per Transcript")
plt.ylabel("Minutes per transcript")
plt.tight_layout()
plt.savefig(OUT / "figure2_processing_time.png", dpi=300)
plt.show()

# --- Figure 3: Error rate (bar) ---
plt.figure()
plt.bar(["Baseline", "Hybrid"], [kpis["error_rate_percent"]["baseline"], kpis["error_rate_percent"]["hybrid"]])
plt.title("Error Rate Comparison")
plt.ylabel("Error rate (%)")
plt.tight_layout()
plt.savefig(OUT / "figure3_error_rate.png", dpi=300)
plt.show()

# --- Figure 1: Workflow diagram + Swimlane ---
if HAS_GRAPHVIZ:
    from graphviz import Digraph

    # Figure 1: End-to-end workflow
    dot = Digraph("Figure1_Workflow", format="png")
    dot.attr(rankdir="LR")
    dot.attr('node', shape="rectangle", style="rounded,filled", fillcolor="lightgrey", fontsize="12")
    dot.node("Req", "Transcript Request\n(Student/Admin)")
    dot.node("RPA", "RPA Orchestrator (UiPath)\n- SIS retrieval\n- Template formatting\n- Dispatch control")
    dot.node("OCR", "OCR Module (Tesseract / UiPath DU)\n- Preprocessing\n- Text extraction")
    dot.node("NLP", "NLP Module (Python: NLTK, spaCy)\n- Parsing & validation\n- Anomaly detection")
    dot.node("Compliance", "Privacy & Compliance\n- AES-256 / TLS\n- RBAC\n- FERPA/GDPR logs")
    dot.node("Out", "Final Transcript\n(Secure email / portal)")
    dot.edge("Req", "RPA")
    dot.edge("Req", "OCR", label="Scanned docs")
    dot.edge("OCR", "NLP")
    dot.edge("NLP", "Compliance")
    dot.edge("RPA", "Compliance")
    dot.edge("Compliance", "Out")
    dot.render(str(OUT / "figure1_workflow_diagram"))

    # Swimlane detail
    swim = Digraph("Proposed_Methodology_Detailed", format="png")
    swim.attr(rankdir="LR", size="10,6")
    with swim.subgraph(name="cluster_RPA") as c:
        c.attr(label="RPA Track (UiPath)", style="filled", color="lightblue", fontsize="14")
        c.node("RPA1", "Retrieve SIS Data")
        c.node("RPA2", "Apply Template")
        c.node("RPA3", "Secure Dispatch")
        c.edges([("RPA1", "RPA2"), ("RPA2", "RPA3")])
    with swim.subgraph(name="cluster_AI") as c:
        c.attr(label="AI Track (Python)", style="filled", color="lightyellow", fontsize="14")
        c.node("AI1", "OCR (Tesseract/UiPath DU)\nPreprocess + Extract")
        c.node("AI2", "NLP (NLTK/spaCy)\nParse + Validate + Detect")
        c.edge("AI1", "AI2")
    swim.node("Comp", "Privacy & Compliance\nAES/TLS, RBAC, Audit")
    swim.node("Out", "Final Transcript")
    swim.node("In", "Transcript Request\n(Digital/Scanned)")
    swim.edge("In", "RPA1", label="Digital")
    swim.edge("In", "AI1",  label="Scanned")
    swim.edge("RPA3", "Comp")
    swim.edge("AI2", "Comp")
    swim.edge("Comp", "Out")
    swim.render(str(OUT / "proposed_methodology_detailed"))

    print("Saved Figure 1:", OUT / "figure1_workflow_diagram.png")
    print("Saved Swimlane:", OUT / "proposed_methodology_detailed.png")
else:
    print("Graphviz not available. Re-run installs at the top if figures are missing.")

# --- Summary JSON ---
summary = {
    "artifacts": {
        "table1": str(table1_path),
        "figure1_workflow": str(OUT / "figure1_workflow_diagram.png"),
        "figure2_processing_time": str(OUT / "figure2_processing_time.png"),
        "figure3_error_rate": str(OUT / "figure3_error_rate.png"),
        "swimlane": str(OUT / "proposed_methodology_detailed.png"),
        "missing_values": str(OUT / "missing_values.png") if miss.sum() > 0 else None,
        "correlation_matrix": str(OUT / "correlation_matrix.png") if len(numeric_cols) >= 2 else None
    },
    "kpis": kpis,
    "improvements": improvements,
    "target": {"column": target_col, "task": task_type}
}
with open(OUT / "run_summary.json", "w") as f:
    json.dump(summary, f, indent=2)

print("\nDone. All artifacts saved under:", OUT)